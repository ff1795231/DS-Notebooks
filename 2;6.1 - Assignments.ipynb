{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nHTErl53-Of"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI5HoDfm3-Oi"
      },
      "source": [
        "# Module Project: Decision Trees\n",
        "\n",
        "This week, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or functional needs repair.\n",
        "\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Sign up for a [Kaggle](https://www.kaggle.com/) account. Join the kaggle competition, and download the water pump dataset.\n",
        "- **Task 2:** Use `wrangle` function to import training and test data.\n",
        "- **Task 3:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and validation sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build and train `model_dt`.\n",
        "- **Task 7:** Calculate the training and validation accuracy score for your model.\n",
        "- **Task 8:** Adjust model's `max_depth` to reduce overfitting.\n",
        "- **Task 9 `stretch goal`:** Create a horizontal bar chart showing the 10 most important features for your model.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!pip install category_encoders==2.*\n",
        "!pip install pandas_profiling==2.*\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from pandas_profiling import ProfileReport\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "A4VdIjsE4XlW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/Kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA4PQsDu6aVe",
        "outputId": "556c7992-9106-43d8-b2fa-26c0b9159665"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qdu6Uon3-Oj"
      },
      "source": [
        "# Kaggle\n",
        "\n",
        "**Task 1:** [Sign up for a Kaggle account](https://www.kaggle.com/), if you donâ€™t already have one. **We recommend that you choose a username that's based on your name, since you might include it in your resume in the future.** Go to our Kaggle competition website (the URL is given on Canvas). Go to the **Rules** page. Accept the rules of the competition and download the dataset. Notice that the **Rules** page also has instructions for the Submission process. The **Data** page has feature definitions.\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ncIdJAf63-Ok"
      },
      "outputs": [],
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08]),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         index_col='id')\n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(100).T.duplicated().index\n",
        "                 if df.head(100).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GJm5X7K3-Ol"
      },
      "source": [
        "**Task 1:** Using the `wrangle` function above, read the `train_features.csv` and  `train_labels.csv` files into the DataFrame `df`. Next, use the same function to read the test set `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OeIOBvVd3-Ol"
      },
      "outputs": [],
      "source": [
        "df = wrangle('train_features.csv', 'train_labels.csv')\n",
        "X_test = wrangle('test_features.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEPGze2M3-Ol"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sYxcjfan3-Om"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = 'status_group')\n",
        "y = df['status_group']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-hig8Sk3-Om"
      },
      "source": [
        "**Task 4:** Using a randomized split, divide `X` and `y` into a training set (`X_train`, `y_train`) and a validation set (`X_val`, `y_val`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fJ5c0FfQ3-Om"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 666)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3pfrJhi3-On"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CD3EVV-V3-On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178633eb-a0f0-4963-8950-a2841caa61bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 0.5429828068772491\n"
          ]
        }
      ],
      "source": [
        "baseline_acc = y.value_counts(normalize = True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pHS7kyq3-On"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_dt`, and fit it to your training data. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` predictor.\n",
        "\n",
        "**Note:** Don't forget to set the `random_state` parameter for your `DecisionTreeClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mIKmklxI3-On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0142a4a2-5f7d-4ac7-a43e-a02c6dcdf526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
              "                                      'scheme_management', 'permit',\n",
              "                                      'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'payment_type', 'water_quality',\n",
              "                                      'quality_group', 'quantity', 'source',\n",
              "                                      'source_type', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoin...\n",
              "                                          'mapping': communal standpipe multiple    1\n",
              "communal standpipe             2\n",
              "hand pump                      3\n",
              "other                          4\n",
              "improved spring                5\n",
              "dam                            6\n",
              "cattle trough                  7\n",
              "NaN                           -2\n",
              "dtype: int64},\n",
              "                                         {'col': 'waterpoint_type_group',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': communal standpipe    1\n",
              "hand pump             2\n",
              "other                 3\n",
              "improved spring       4\n",
              "dam                   5\n",
              "cattle trough         6\n",
              "NaN                  -2\n",
              "dtype: int64}])),\n",
              "                ('simpleimputer', SimpleImputer()),\n",
              "                ('decisiontreeclassifier',\n",
              "                 DecisionTreeClassifier(max_depth=11, random_state=666))])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model_dt = make_pipeline(OrdinalEncoder(),\n",
        "                         SimpleImputer(strategy = 'mean'),\n",
        "                         DecisionTreeClassifier(random_state = 666, max_depth = 11))\n",
        "\n",
        "model_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJKGgwJg3-Oo"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and validation accuracy scores for `model_dt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Hy8wvn3-3-Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe96516-715b-4a06-9123-ca37c70a16c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy Score: 0.7862734644630882\n",
            "Validation Accuracy Score: 0.7473905723905724\n"
          ]
        }
      ],
      "source": [
        "training_acc = accuracy_score(y_train, model_dt.predict(X_train))\n",
        "val_acc = accuracy_score(y_val, model_dt.predict(X_val))\n",
        "\n",
        "print('Training Accuracy Score:', training_acc)\n",
        "print('Validation Accuracy Score:', val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Jv4w7D3-Oo"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 8:** Is there a large difference between your training and validation accuracy? If so, experiment with different setting for `max_depth` in your `DecisionTreeClassifier` to reduce the amount of overfitting in your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pRFE9gaI3-Oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496968cc-0607-4f42-bfaa-516d0ead1c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.7144420438283903,\n",
              "  0.7368613036280479,\n",
              "  0.7608518757540896,\n",
              "  0.7862734644630882,\n",
              "  0.8139397850669211,\n",
              "  0.8440753107550717,\n",
              "  0.8752490249445832,\n",
              "  0.903308173630012],\n",
              " [0.7095959595959596,\n",
              "  0.7251683501683501,\n",
              "  0.7387205387205387,\n",
              "  0.7473905723905724,\n",
              "  0.7505050505050505,\n",
              "  0.7527777777777778,\n",
              "  0.755976430976431,\n",
              "  0.7560606060606061])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Use this cell to experiment and then change \n",
        "# your model hyperparameters in Task 6\n",
        "\n",
        "depths = range(5, 20, 2)\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "for depth in depths:\n",
        "  tree_model = make_pipeline(\n",
        "      OrdinalEncoder(),\n",
        "      SimpleImputer(),\n",
        "      DecisionTreeClassifier(max_depth = depth, random_state = 666))\n",
        "  tree_model.fit(X_train,y_train)\n",
        "  train_acc.append(tree_model.score(X_train, y_train))\n",
        "  val_acc.append(tree_model.score(X_val, y_val))\n",
        "    \n",
        "train_acc, val_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Nja-2H3-Oo"
      },
      "source": [
        "# VII. Communicate Results\n",
        "\n",
        "**Task 9 `stretch goal`:** Create a horizontal barchart that shows the the 10 most important features for model_dt, sorted by value.\n",
        "\n",
        "**Note:** [`DecisionTreeClassifier.feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreecla#sklearn.tree.DecisionTreeClassifier.feature_importances_) returns values that are different from [`LogisticRegression.coef_`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). All the values will be positive, and they will sum to `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OodN18M43-Oo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}